{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Analyzing Hacker News Posts Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker News is a platform, extremely popular in technology and startup circles, where users share their posts and receives some votes and comments. We would be analyzing these posts along with some additional data like date of creation, upvotes, comments and so on, to derive some useful insights. The [data set]('https://www.kaggle.com/hacker-news/hacker-news-posts') used has been cut down from almost 300,000 rows to approximately 20,000 rows for our analysis purposes by removing those posts' data which have incomplete information such as zero comments or upvotes.\n",
    "\n",
    "The columns of the data set are as follows:\n",
    "\n",
    "| Column  |About |\n",
    "|:--------|:------|\n",
    "|id | the unique identifier from Hacker News for the post|\n",
    "|title | the title of the post|\n",
    "|url | the URL that the posts links to, if the post has a URL|\n",
    "|num_points| the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes|\n",
    "|num_comments | the number of comments on the post|\n",
    "|author | the username of the person who submitted the post|\n",
    "|created_at | the date and time of the post's submission|\n",
    "\n",
    "We are specifically interested in posts beggining with `Ask HN` or `Show HN`. `Ask HN` are the posts in which users asks a question to the other users on Hacker News and `Show HN` are the posts in which users showcase something of their own or just anything interesting. \n",
    "\n",
    "We would be comparing these two posts to determine the following:\n",
    "* Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing the required Hacker News data set__\n",
    "\n",
    "Let's start by importing the data set, `hacker_news.csv` as a list of lists and storing it in `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing 'reader' from 'csv' module\n",
    "from csv import reader\n",
    "\n",
    "# Opening the file and creating a 'reader' object\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the above data set contains the header columns list as the first row, we will remove it from the set and store it in the `headers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Storing headers of data in a variable\n",
    "headers = hn[0]\n",
    "\n",
    "# Assigning the data set with minus header row\n",
    "hn = hn[1:]\n",
    "\n",
    "# Inspecting the data set\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data cleaning__\n",
    "\n",
    "Now that we have the data set, let's start preparing it for analysis. Since, we require posts that either starts with `Ask HN` or `Show HN`, we will isolate this data in other lists. We will use a string method `string.startswith('word')` to check whether a string starts with provided phrase or word. It will return `True` if it does, otherwise `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN posts: 1744\n",
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']]\n",
      "\n",
      "\n",
      "Show HN posts: 1162\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']]\n",
      "\n",
      "\n",
      "Other posts: 17194\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "# Defining some empty lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "# Looping over hn \n",
    "for row in hn:\n",
    "    \n",
    "    # Extracting the title and converting it to lower case\n",
    "    title = row[1].lower()\n",
    "    \n",
    "    # Checking whether the title starts with 'ask hn' or 'show hn' \n",
    "    # and appending in respective lists.\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('Ask HN posts:',len(ask_posts))\n",
    "print(ask_posts[:2])\n",
    "print('\\n')\n",
    "print('Show HN posts:',len(show_posts))\n",
    "print(show_posts[:2])\n",
    "print('\\n')\n",
    "print('Other posts:',len(other_posts))\n",
    "print(other_posts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Finding the average number of comments on `Ask HN` and `Show HN` posts__\n",
    "\n",
    "Now that we have different data for the `Ask HN` and `Show HN`, we can now start analysing data. We will determine whether `Ask HN` or `Show HN` posts receive more comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : <class 'str'>\n",
      "title : <class 'str'>\n",
      "url : <class 'str'>\n",
      "num_points : <class 'str'>\n",
      "num_comments : <class 'str'>\n",
      "author : <class 'str'>\n",
      "created_at : <class 'str'>\n",
      "Average ask comments : 14.038417431192661\n",
      "Average show comments : 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Investigating the headers' data types\n",
    "for column in headers:\n",
    "    print(column,':',type(column))\n",
    "\n",
    "# Finding the average number of comments for:\n",
    "# 1) 'Ask HN' posts\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comment = int(row[4])\n",
    "    total_ask_comments += num_comment\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('Average ask comments : {}'.format(avg_ask_comments))\n",
    "\n",
    "# 2) 'Show HN' posts\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comment = int(row[4])\n",
    "    total_show_comments += num_comment\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('Average show comments : {}'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is evident from the above output, the average number of comments on `Ask HN` are greater than the `Show HN` posts. The reason could be because of the nature of `Ask HN` post which is basically a question being asked and thus engross much more audience as compared to the the `Show HN` post which is more like a general discussion, statement or a fact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determining the most popular post-creation time__\n",
    "\n",
    "Since the `Ask HN` posts seems more popular, we would continue our analysis on those only. We will determine if `Ask HN` posts created at certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "* Calculate the number of `Ask HN` posts created in each hour of the day.\n",
    "* Calculate the average number of comments `Ask HN` posts receive by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from result_list: [['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29]]\n",
      "\n",
      "\n",
      "Posts per hour: {'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "Comments per hour: {'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "# Importing required 'datetime' module\n",
    "import datetime as dt\n",
    "\n",
    "# Initializing an empty list for date of post creation and number of comments\n",
    "# on the post\n",
    "result_list = []\n",
    "\n",
    "# Looping over 'Ask HN' posts\n",
    "for row in ask_posts:\n",
    "    \n",
    "    # Storing the date and comments in variables\n",
    "    created_at = row[-1]\n",
    "    num_comments = int(row[-3])\n",
    "    \n",
    "    # Appending the above data to the list created before\n",
    "    result_list.append([created_at, num_comments])\n",
    "print('Sample from result_list:',result_list[:2])    \n",
    "print('\\n')\n",
    "\n",
    "# Initializing two empty dictionaries for creating a frequency table for number\n",
    "# of posts created per given hour and number of comments on the posts at each\n",
    "# hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    \n",
    "    # Creating a datetime object from the string datetime column\n",
    "    date_parsed = dt.datetime.strptime(row[0],'%m/%d/%Y %H:%M') \n",
    "    \n",
    "    # Formatting the datetime object to obtain hour as string\n",
    "    hr=date_parsed.strftime('%H')\n",
    "    \n",
    "    # Checking whether the above 'hour' exists as a key in the dictionaries or not\n",
    "    # and updating the both the dictionaries as follows:\n",
    "    # if hr exists in counts_by_hr then:\n",
    "    #    update the key-value pair of hr in both dictionaries by 1\n",
    "    # else:\n",
    "    #    create the key-value pair of hr in both dictionaries with initialization at 1\n",
    "    if hr in counts_by_hour:\n",
    "        counts_by_hour[hr] += 1\n",
    "        comments_by_hour[hr] += row[1]\n",
    "    else:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = row[1]\n",
    "        \n",
    "print('Posts per hour:',counts_by_hour)\n",
    "print('\\n')\n",
    "print('Comments per hour:',comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating the average number of comments per `Ask HN` post for each hour__\n",
    "\n",
    "Now that we have the data of number of posts and comments per hour, we can determine the average number of comments on a post for a given hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for storing average number of comments per post\n",
    "# for each hour i.e., number of comments per post per hour / num of posts per \n",
    "# hour\n",
    "avg_by_hour = []\n",
    "for post in counts_by_hour:\n",
    "    avg_comments_per_post = comments_by_hour[post] / counts_by_hour[post]\n",
    "    \n",
    "    # Appending the data, time and averaged comments to the above list\n",
    "    avg_by_hour.append([post,avg_comments_per_post])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sorting the data for better accessibility and readability__\n",
    "\n",
    "Now that we have the data, we can finally make a decision on the hour of the day on which the most comments were posted on a post. But the values are not easy to read since data is not sorted. Let's do so by swapping the values in each row of the above list and storing them in another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swapped list of data\n",
      "[5.5777777777777775, '09']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[16.796296296296298, '16']\n",
      "[7.985294117647059, '23']\n",
      "[9.41095890410959, '12']\n",
      "[11.46, '17']\n",
      "[38.5948275862069, '15']\n",
      "[16.009174311926607, '21']\n",
      "[21.525, '20']\n",
      "[23.810344827586206, '02']\n",
      "[13.20183486238532, '18']\n",
      "[7.796296296296297, '03']\n",
      "[10.08695652173913, '05']\n",
      "[10.8, '19']\n",
      "[11.383333333333333, '01']\n",
      "[6.746478873239437, '22']\n",
      "[10.25, '08']\n",
      "[7.170212765957447, '04']\n",
      "[8.127272727272727, '00']\n",
      "[9.022727272727273, '06']\n",
      "[7.852941176470588, '07']\n",
      "[11.051724137931034, '11']\n",
      "\n",
      "\n",
      "Sorting the above data\n",
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n",
      "\n",
      "\n",
      "Top 5 hours for Ask HN posts\n",
      "15:00 EST: 38.59 average comments per post\n",
      "02:00 EST: 23.81 average comments per post\n",
      "20:00 EST: 21.52 average comments per post\n",
      "16:00 EST: 16.80 average comments per post\n",
      "21:00 EST: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for creating a swapped list\n",
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    \n",
    "    # Swapping and appending the values\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "print('Swapped list of data')    \n",
    "for row in swap_avg_by_hour:\n",
    "    print(row)\n",
    "        \n",
    "print('\\n')\n",
    "\n",
    "# Printing a sorted list of above data in descending order of average comments\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print('Sorting the above data')\n",
    "for row in sorted_swap:\n",
    "    print(row)\n",
    "\n",
    "# Printing the top 5 values out of the above list\n",
    "print('\\n')\n",
    "print('Top 5 hours for Ask HN posts')\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = row[1]\n",
    "    avg_comments = row[0]\n",
    "    parsed_date = dt.datetime.strptime(hour,'%H')\n",
    "    converted_date = parsed_date.strftime('%H:%M')\n",
    "    \n",
    "    print('{} EST: {:.2f} average comments per post'.format(converted_date,avg_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results suggests that the time period from `15:00 to 16:00 EST` that is Eastern Standard Time, receives the highest number of comments on the `Ask HN` posts. To understand it in the terms of `IST` that is, `Indian Standard Time` let's do a conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask HN post in Indian Standard Time\n",
      "01:00 IST: 38.59 average comments per post\n",
      "12:00 IST: 23.81 average comments per post\n",
      "06:00 IST: 21.52 average comments per post\n",
      "02:00 IST: 16.80 average comments per post\n",
      "07:00 IST: 16.01 average comments per post\n",
      "Hour with least comments: 19:00 IST with 5.58 comments\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for storing IST values\n",
    "ist_data = []\n",
    "\n",
    "# Importing 'pytz' module for defining the timezone of original values as 'EST'\n",
    "import pytz\n",
    "for row in sorted_swap:\n",
    "    avg_comment = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data.append([avg_comment,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for Ask HN post in Indian Standard Time')    \n",
    "for row in ist_data[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_comment = row[0]\n",
    "        print('{} IST: {:.2f} average comments per post'.format(time_data,avg_comment))\n",
    "print('Hour with least comments: {} IST with {:.2f} comments'.format(ist_data[-1][-1],ist_data[-1][0]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data seems to be much better. It can be easily deduced that difference between the hour with maximum average number of comments and the minimum average number of comments comes at a percentage difference of approximately `30%`, which is quite significant. Hence, we can say that the timings of post creation does infact impacts the number of comments and thus audience engagement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we analyzed `Ask HN` posts and `Show HN` posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as `Ask HN` post and created between `15:00 and 16:00 EST` `(1:00 and 2:00 IST)`\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, `Ask HN` posts received more comments on average and `Ask HN` posts created between `15:00 and 16:00` `(1:00 and 2:00 IST)` received the most comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more useful insights from the data set\n",
    "1. __Determining if `Show HN` or `Ask HN` receives more points on average__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 'Ask HN' points: 15.06\n",
      "Average 'Show HN' points: 27.56\n"
     ]
    }
   ],
   "source": [
    "# Initializing two lists to store posts' titles and points\n",
    "ask_points = []\n",
    "show_points = []\n",
    "\n",
    "# Appending required data\n",
    "for row in ask_posts:\n",
    "    ask_points.append([row[1],int(row[3])])\n",
    "for row in show_posts:\n",
    "    show_points.append([row[1],int(row[3])])\n",
    "\n",
    "# Calculating average points for Ask HN posts    \n",
    "summed = 0    \n",
    "for row in ask_points:\n",
    "    point = row[1]\n",
    "    summed += point\n",
    "avg_ask_points = summed / len(ask_points)\n",
    "\n",
    "# Calculating average points for Show HN posts\n",
    "summed = 0    \n",
    "for row in show_points:\n",
    "    point = row[1]\n",
    "    summed += point\n",
    "avg_show_points = summed / len(show_points)\n",
    "\n",
    "print('Average \\'Ask HN\\' points: {:.2f}'.format(avg_ask_points))\n",
    "print('Average \\'Show HN\\' points: {:.2f}'.format(avg_show_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the above output that the `Show HN` posts have greater points as compared to `Ask HN` posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Determining if posts created at a certain time are more likely to receive more points__\n",
    "\n",
    "Since, `Show HN` posts have more number of average points, we will restrict our analysis to these only. In order to find out whether the posts created at certain time receive more points, we will do the following:\n",
    "* Determining the number of `Show HN` posts created at different hours.\n",
    "* Determining the average number of points received on the `Show HN` posts at particular hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: [[datetime.datetime(2015, 11, 25, 14, 3), 26], [datetime.datetime(2015, 11, 29, 22, 46), 747], [datetime.datetime(2016, 4, 28, 18, 5), 1], [datetime.datetime(2016, 7, 28, 7, 11), 3], [datetime.datetime(2016, 1, 9, 20, 45), 1]]\n",
      "\n",
      "\n",
      "Posts per hour: {'14': 86, '22': 46, '18': 61, '07': 26, '20': 60, '05': 19, '16': 93, '19': 55, '15': 78, '03': 27, '17': 93, '06': 16, '02': 30, '13': 99, '08': 34, '21': 47, '04': 26, '11': 44, '12': 61, '23': 36, '09': 30, '01': 28, '10': 36, '00': 31}\n",
      "\n",
      "\n",
      "Points per hour: {'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n"
     ]
    }
   ],
   "source": [
    "# Initializing a list for storing Show HN posts' creation time and points\n",
    "mod_show_posts = []\n",
    "\n",
    "# Looping over Show HN posts data set and collecting required columns\n",
    "for row in show_posts:\n",
    "    date_post = row[-1]\n",
    "    points_post = int(row[3])\n",
    "    \n",
    "    # Parsing the date using datetime.strptime() method \n",
    "    date_post = dt.datetime.strptime(date_post,'%m/%d/%Y %H:%M')\n",
    "    \n",
    "    # Appending the data to the above list\n",
    "    mod_show_posts.append([date_post,points_post])\n",
    "\n",
    "# Checking the data set\n",
    "print('Sample data:',mod_show_posts[:5])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Initializing two empty dictionaries for creating frequency tables for number\n",
    "# of posts created per hour and number of points received per hour per\n",
    "show_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "\n",
    "for row in mod_show_posts:\n",
    "    points = row[1]\n",
    "    date = row[0]\n",
    "    \n",
    "    # Extracting the hour out of the datetime object\n",
    "    hour = date.strftime('%H')\n",
    "    \n",
    "    # Checking if hour exists as a key in both dictionaries\n",
    "    if hour in show_by_hour:\n",
    "        show_by_hour[hour] += 1\n",
    "        points_by_hour[hour] += points\n",
    "    else:\n",
    "        show_by_hour[hour] = 1\n",
    "        points_by_hour[hour] = points\n",
    "        \n",
    "print('Posts per hour:',show_by_hour)\n",
    "print('\\n')\n",
    "print('Points per hour:',points_by_hour)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14', 25.430232558139537],\n",
       " ['22', 40.34782608695652],\n",
       " ['18', 36.31147540983606],\n",
       " ['07', 19.0],\n",
       " ['20', 30.316666666666666],\n",
       " ['05', 5.473684210526316],\n",
       " ['16', 28.322580645161292],\n",
       " ['19', 30.945454545454545],\n",
       " ['15', 28.564102564102566],\n",
       " ['03', 25.14814814814815],\n",
       " ['17', 27.107526881720432],\n",
       " ['06', 23.4375],\n",
       " ['02', 11.333333333333334],\n",
       " ['13', 24.626262626262626],\n",
       " ['08', 15.264705882352942],\n",
       " ['21', 18.425531914893618],\n",
       " ['04', 14.846153846153847],\n",
       " ['11', 33.63636363636363],\n",
       " ['12', 41.68852459016394],\n",
       " ['23', 42.388888888888886],\n",
       " ['09', 18.433333333333334],\n",
       " ['01', 25.0],\n",
       " ['10', 18.916666666666668],\n",
       " ['00', 37.83870967741935]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a list for storing averaged points per post per hour\n",
    "avg_points_post = []\n",
    "for hour in show_by_hour:\n",
    "    post_count = show_by_hour[hour]\n",
    "    post_points = points_by_hour[hour]\n",
    "    \n",
    "    # Average points per post for every hour = no. of points per hour / no. of posts per hour\n",
    "    avg_data =  post_points / post_count\n",
    "    avg_points_post.append([hour,avg_data])\n",
    "\n",
    "avg_points_post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[42.388888888888886, '23'],\n",
       " [41.68852459016394, '12'],\n",
       " [40.34782608695652, '22'],\n",
       " [37.83870967741935, '00'],\n",
       " [36.31147540983606, '18'],\n",
       " [33.63636363636363, '11'],\n",
       " [30.945454545454545, '19'],\n",
       " [30.316666666666666, '20'],\n",
       " [28.564102564102566, '15'],\n",
       " [28.322580645161292, '16'],\n",
       " [27.107526881720432, '17'],\n",
       " [25.430232558139537, '14'],\n",
       " [25.14814814814815, '03'],\n",
       " [25.0, '01'],\n",
       " [24.626262626262626, '13'],\n",
       " [23.4375, '06'],\n",
       " [19.0, '07'],\n",
       " [18.916666666666668, '10'],\n",
       " [18.433333333333334, '09'],\n",
       " [18.425531914893618, '21'],\n",
       " [15.264705882352942, '08'],\n",
       " [14.846153846153847, '04'],\n",
       " [11.333333333333334, '02'],\n",
       " [5.473684210526316, '05']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list with swapped values for better readability    \n",
    "swapped = []    \n",
    "for row in avg_points_post:\n",
    "    swapped.append([row[1],row[0]])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Sorting values in descending order for better accessibility\n",
    "sorted_swap = sorted(swapped,reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show HN posts in Eastern Standard Time\n",
      "23:00 EST: 42.39 average points per post\n",
      "12:00 EST: 41.69 average points per post\n",
      "22:00 EST: 40.35 average points per post\n",
      "00:00 EST: 37.84 average points per post\n",
      "18:00 EST: 36.31 average points per post\n",
      "Hour with least average points: 05:00 EST with 5.47 points\n"
     ]
    }
   ],
   "source": [
    "# Printing the top 5 hours with most points per page\n",
    "print('Top 5 hours for Show HN posts in Eastern Standard Time')\n",
    "for row in sorted_swap[:5]:\n",
    "    print('{}:00 EST: {:.2f} average points per post'.format(row[1],row[0]))\n",
    "\n",
    "# Printing the hour with least points per page\n",
    "print('Hour with least average points: {}:00 EST with {:.2f} points'.format(sorted_swap[-1][1],sorted_swap[-1][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show HN post in Indian Standard Time\n",
      "09:00 IST: 42.39 average points per post\n",
      "22:00 IST: 41.69 average points per post\n",
      "08:00 IST: 40.35 average points per post\n",
      "10:00 IST: 37.84 average points per post\n",
      "04:00 IST: 36.31 average points per post\n",
      "Hour with least comments: 15:00 IST with 5.47 comments\n"
     ]
    }
   ],
   "source": [
    "# Initializing a list to store IST converted values\n",
    "ist_data_2 = []\n",
    "\n",
    "# Importing 'pytz' module for defining the timezone of original values as 'EST'\n",
    "import pytz\n",
    "for row in sorted_swap:\n",
    "    avg_points = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data_2.append([avg_points,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for Show HN post in Indian Standard Time')    \n",
    "for row in ist_data_2[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_points = row[0]\n",
    "        print('{} IST: {:.2f} average points per post'.format(time_data,avg_points))\n",
    "print('Hour with least comments: {} IST with {:.2f} comments'.format(ist_data_2[-1][-1],ist_data_2[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above output that time between `23:00 and 24:00 EST` `(09:00 and 10:00 IST)` is the best to create a `Show HN` post and receive maximum points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
